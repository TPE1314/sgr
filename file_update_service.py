#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import shutil
import tempfile
import zipfile
import tarfile
import logging
import hashlib
import json
from typing import Dict, List, Tuple, Optional
from datetime import datetime
from pathlib import Path
from database import DatabaseManager
from config_manager import ConfigManager
from update_service import UpdateService

logger = logging.getLogger(__name__)

class FileUpdateService:
    def __init__(self):
        self.config = ConfigManager()
        self.db = DatabaseManager(self.config.get_db_file())
        self.update_service = UpdateService()
        self.temp_dir = "temp_updates"
        self.allowed_extensions = {'.py', '.ini', '.txt', '.md', '.sh', '.json', '.yml', '.yaml'}
        self.protected_files = {'telegram_bot.db', '.version'}
        
    def validate_file(self, file_path: str, file_name: str) -> Tuple[bool, str]:
        """éªŒè¯ä¸Šä¼ çš„æ–‡ä»¶"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            file_ext = Path(file_name).suffix.lower()
            if file_ext not in self.allowed_extensions:
                return False, f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}"
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å° (æœ€å¤§5MB)
            file_size = os.path.getsize(file_path)
            if file_size > 5 * 1024 * 1024:
                return False, f"æ–‡ä»¶è¿‡å¤§: {file_size / 1024 / 1024:.1f}MB (æœ€å¤§5MB)"
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å—ä¿æŠ¤çš„æ–‡ä»¶
            if file_name in self.protected_files:
                return False, f"å—ä¿æŠ¤çš„æ–‡ä»¶ä¸èƒ½æ›¿æ¢: {file_name}"
            
            # å¯¹äºPythonæ–‡ä»¶ï¼Œè¿›è¡Œè¯­æ³•æ£€æŸ¥
            if file_ext == '.py':
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        code = f.read()
                    compile(code, file_name, 'exec')
                except SyntaxError as e:
                    return False, f"Pythonè¯­æ³•é”™è¯¯: {e}"
                except UnicodeDecodeError:
                    return False, "æ–‡ä»¶ç¼–ç é”™è¯¯ï¼Œè¯·ä½¿ç”¨UTF-8ç¼–ç "
            
            return True, "æ–‡ä»¶éªŒè¯é€šè¿‡"
            
        except Exception as e:
            logger.error(f"æ–‡ä»¶éªŒè¯å¤±è´¥: {e}")
            return False, f"æ–‡ä»¶éªŒè¯å¤±è´¥: {str(e)}"
    
    def analyze_file_changes(self, file_path: str, target_name: str) -> Dict:
        """åˆ†ææ–‡ä»¶å˜æ›´"""
        try:
            analysis = {
                'file_name': target_name,
                'file_size': os.path.getsize(file_path),
                'file_type': Path(target_name).suffix.lower(),
                'exists': os.path.exists(target_name),
                'changes': [],
                'risks': [],
                'recommendations': []
            }
            
            # å¦‚æœç›®æ ‡æ–‡ä»¶å­˜åœ¨ï¼Œæ¯”è¾ƒå·®å¼‚
            if analysis['exists']:
                try:
                    # æ¯”è¾ƒæ–‡ä»¶å¤§å°
                    old_size = os.path.getsize(target_name)
                    size_diff = analysis['file_size'] - old_size
                    analysis['changes'].append(f"æ–‡ä»¶å¤§å°: {old_size} -> {analysis['file_size']} ({size_diff:+d} bytes)")
                    
                    # æ¯”è¾ƒæ–‡ä»¶å“ˆå¸Œ
                    old_hash = self._get_file_hash(target_name)
                    new_hash = self._get_file_hash(file_path)
                    
                    if old_hash == new_hash:
                        analysis['changes'].append("æ–‡ä»¶å†…å®¹ç›¸åŒï¼Œæ— éœ€æ›´æ–°")
                    else:
                        analysis['changes'].append("æ–‡ä»¶å†…å®¹å·²ä¿®æ”¹")
                        
                        # å¯¹äºPythonæ–‡ä»¶ï¼Œæ£€æŸ¥å¯¼å…¥å’Œå‡½æ•°
                        if analysis['file_type'] == '.py':
                            self._analyze_python_changes(target_name, file_path, analysis)
                            
                except Exception as e:
                    analysis['changes'].append(f"æ— æ³•æ¯”è¾ƒå·®å¼‚: {e}")
            else:
                analysis['changes'].append("æ–°æ–‡ä»¶")
            
            # é£é™©è¯„ä¼°
            self._assess_risks(target_name, analysis)
            
            # ç”Ÿæˆå»ºè®®
            self._generate_recommendations(analysis)
            
            return analysis
            
        except Exception as e:
            logger.error(f"åˆ†ææ–‡ä»¶å˜æ›´å¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _get_file_hash(self, file_path: str) -> str:
        """è·å–æ–‡ä»¶å“ˆå¸Œå€¼"""
        hasher = hashlib.md5()
        with open(file_path, 'rb') as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hasher.update(chunk)
        return hasher.hexdigest()
    
    def _analyze_python_changes(self, old_file: str, new_file: str, analysis: Dict):
        """åˆ†æPythonæ–‡ä»¶çš„å˜æ›´"""
        try:
            import ast
            
            def get_python_info(file_path):
                with open(file_path, 'r', encoding='utf-8') as f:
                    tree = ast.parse(f.read())
                
                imports = []
                functions = []
                classes = []
                
                for node in ast.walk(tree):
                    if isinstance(node, (ast.Import, ast.ImportFrom)):
                        if isinstance(node, ast.Import):
                            imports.extend([alias.name for alias in node.names])
                        else:
                            imports.append(node.module or '')
                    elif isinstance(node, ast.FunctionDef):
                        functions.append(node.name)
                    elif isinstance(node, ast.ClassDef):
                        classes.append(node.name)
                
                return imports, functions, classes
            
            old_imports, old_functions, old_classes = get_python_info(old_file)
            new_imports, new_functions, new_classes = get_python_info(new_file)
            
            # åˆ†æå¯¼å…¥å˜æ›´
            added_imports = set(new_imports) - set(old_imports)
            removed_imports = set(old_imports) - set(new_imports)
            
            if added_imports:
                analysis['changes'].append(f"æ–°å¢å¯¼å…¥: {', '.join(added_imports)}")
            if removed_imports:
                analysis['changes'].append(f"ç§»é™¤å¯¼å…¥: {', '.join(removed_imports)}")
            
            # åˆ†æå‡½æ•°å˜æ›´
            added_functions = set(new_functions) - set(old_functions)
            removed_functions = set(old_functions) - set(new_functions)
            
            if added_functions:
                analysis['changes'].append(f"æ–°å¢å‡½æ•°: {', '.join(added_functions)}")
            if removed_functions:
                analysis['changes'].append(f"ç§»é™¤å‡½æ•°: {', '.join(removed_functions)}")
                analysis['risks'].append("ç§»é™¤å‡½æ•°å¯èƒ½å½±å“å…¶ä»–æ¨¡å—")
            
            # åˆ†æç±»å˜æ›´
            added_classes = set(new_classes) - set(old_classes)
            removed_classes = set(old_classes) - set(new_classes)
            
            if added_classes:
                analysis['changes'].append(f"æ–°å¢ç±»: {', '.join(added_classes)}")
            if removed_classes:
                analysis['changes'].append(f"ç§»é™¤ç±»: {', '.join(removed_classes)}")
                analysis['risks'].append("ç§»é™¤ç±»å¯èƒ½å½±å“å…¶ä»–æ¨¡å—")
                
        except Exception as e:
            analysis['changes'].append(f"Pythonä»£ç åˆ†æå¤±è´¥: {e}")
    
    def _assess_risks(self, target_name: str, analysis: Dict):
        """é£é™©è¯„ä¼°"""
        file_name = Path(target_name).name
        
        # æ ¸å¿ƒæ–‡ä»¶é£é™©è¯„ä¼°
        core_files = {
            'database.py': 'æ•°æ®åº“æ“ä½œæ–‡ä»¶ï¼Œä¿®æ”¹å¯èƒ½å½±å“æ•°æ®å®‰å…¨',
            'config_manager.py': 'é…ç½®ç®¡ç†æ–‡ä»¶ï¼Œä¿®æ”¹å¯èƒ½å½±å“ç³»ç»Ÿç¨³å®šæ€§',
            'submission_bot.py': 'æŠ•ç¨¿æœºå™¨äººä¸»æ–‡ä»¶ï¼Œä¿®æ”¹éœ€é‡å¯ç”Ÿæ•ˆ',
            'publish_bot.py': 'å‘å¸ƒæœºå™¨äººä¸»æ–‡ä»¶ï¼Œä¿®æ”¹éœ€é‡å¯ç”Ÿæ•ˆ',
            'control_bot.py': 'æ§åˆ¶æœºå™¨äººä¸»æ–‡ä»¶ï¼Œä¿®æ”¹éœ€é‡å¯ç”Ÿæ•ˆ',
            'config.ini': 'é…ç½®æ–‡ä»¶ï¼Œä¿®æ”¹éœ€é‡å¯ç”Ÿæ•ˆ'
        }
        
        if file_name in core_files:
            analysis['risks'].append(core_files[file_name])
        
        # æ–‡ä»¶ç±»å‹é£é™©è¯„ä¼°
        if analysis['file_type'] == '.py':
            analysis['risks'].append("Pythonæ–‡ä»¶ä¿®æ”¹éœ€è¦é‡å¯ç›¸å…³æœºå™¨äºº")
        elif analysis['file_type'] == '.ini':
            analysis['risks'].append("é…ç½®æ–‡ä»¶ä¿®æ”¹éœ€è¦é‡å¯æœºå™¨äºº")
        elif analysis['file_type'] == '.sh':
            analysis['risks'].append("è„šæœ¬æ–‡ä»¶ä¿®æ”¹å¯èƒ½å½±å“ç³»ç»Ÿæ“ä½œ")
    
    def _generate_recommendations(self, analysis: Dict):
        """ç”Ÿæˆå»ºè®®"""
        file_name = Path(analysis['file_name']).name
        
        # æ ¹æ®æ–‡ä»¶ç±»å‹ç”Ÿæˆå»ºè®®
        if analysis['file_type'] == '.py':
            analysis['recommendations'].append("å»ºè®®åœ¨æ›´æ–°åé‡å¯ç›¸å…³æœºå™¨äºº")
            analysis['recommendations'].append("å»ºè®®å…ˆåœ¨æµ‹è¯•ç¯å¢ƒéªŒè¯")
        
        if file_name.endswith('_bot.py'):
            analysis['recommendations'].append("æœºå™¨äººæ–‡ä»¶æ›´æ–°åéœ€è¦é‡å¯è¯¥æœºå™¨äºº")
        
        if analysis['file_name'] == 'config.ini':
            analysis['recommendations'].append("é…ç½®æ–‡ä»¶æ›´æ–°åéœ€è¦é‡å¯æ‰€æœ‰æœºå™¨äºº")
        
        if not analysis['exists']:
            analysis['recommendations'].append("è¿™æ˜¯æ–°æ–‡ä»¶ï¼Œè¯·ç¡®è®¤æ–‡ä»¶ä½ç½®æ­£ç¡®")
        
        if analysis.get('risks'):
            analysis['recommendations'].append("å­˜åœ¨é£é™©ï¼Œå»ºè®®å…ˆåˆ›å»ºå¤‡ä»½")
    
    async def update_single_file(self, file_path: str, target_name: str, user_id: int) -> Tuple[bool, str]:
        """æ›´æ–°å•ä¸ªæ–‡ä»¶"""
        try:
            # éªŒè¯æ–‡ä»¶
            valid, msg = self.validate_file(file_path, target_name)
            if not valid:
                return False, msg
            
            # åˆ›å»ºå¤‡ä»½
            backup_success, backup_msg = self.update_service.create_backup()
            if not backup_success:
                logger.warning(f"å¤‡ä»½å¤±è´¥: {backup_msg}")
            
            # å¦‚æœç›®æ ‡æ–‡ä»¶å­˜åœ¨ï¼Œå¤‡ä»½åŸæ–‡ä»¶
            if os.path.exists(target_name):
                backup_name = f"{target_name}.backup.{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                shutil.copy2(target_name, backup_name)
                logger.info(f"åŸæ–‡ä»¶å·²å¤‡ä»½ä¸º: {backup_name}")
            
            # å¤åˆ¶æ–°æ–‡ä»¶
            shutil.copy2(file_path, target_name)
            
            # è®°å½•æ›´æ–°æ“ä½œ
            update_info = {
                'file_name': target_name,
                'updated_by': user_id,
                'update_time': datetime.now().isoformat(),
                'file_size': os.path.getsize(target_name),
                'file_hash': self._get_file_hash(target_name)
            }
            
            self.db.set_config(f'file_update_{target_name}', json.dumps(update_info), user_id)
            
            logger.info(f"æ–‡ä»¶æ›´æ–°æˆåŠŸ: {target_name} (ç”¨æˆ·: {user_id})")
            return True, f"æ–‡ä»¶ {target_name} æ›´æ–°æˆåŠŸ"
            
        except Exception as e:
            logger.error(f"æ–‡ä»¶æ›´æ–°å¤±è´¥: {e}")
            return False, f"æ–‡ä»¶æ›´æ–°å¤±è´¥: {str(e)}"
    
    async def extract_and_update_archive(self, file_path: str, user_id: int) -> Tuple[bool, str]:
        """è§£å‹å¹¶æ›´æ–°å‹ç¼©åŒ…ä¸­çš„æ–‡ä»¶"""
        try:
            # åˆ›å»ºä¸´æ—¶ç›®å½•
            os.makedirs(self.temp_dir, exist_ok=True)
            extract_dir = os.path.join(self.temp_dir, f"extract_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
            os.makedirs(extract_dir)
            
            # æ ¹æ®æ–‡ä»¶ç±»å‹è§£å‹
            if file_path.endswith('.zip'):
                with zipfile.ZipFile(file_path, 'r') as zip_ref:
                    zip_ref.extractall(extract_dir)
            elif file_path.endswith(('.tar', '.tar.gz', '.tgz')):
                with tarfile.open(file_path, 'r') as tar_ref:
                    tar_ref.extractall(extract_dir)
            else:
                return False, "ä¸æ”¯æŒçš„å‹ç¼©æ ¼å¼"
            
            # åˆ›å»ºç³»ç»Ÿå¤‡ä»½
            backup_success, backup_msg = self.update_service.create_backup()
            if not backup_success:
                logger.warning(f"ç³»ç»Ÿå¤‡ä»½å¤±è´¥: {backup_msg}")
            
            # åˆ†æå¹¶æ›´æ–°æ–‡ä»¶
            updated_files = []
            failed_files = []
            
            for root, dirs, files in os.walk(extract_dir):
                for file in files:
                    source_path = os.path.join(root, file)
                    relative_path = os.path.relpath(source_path, extract_dir)
                    
                    # éªŒè¯æ–‡ä»¶
                    valid, msg = self.validate_file(source_path, relative_path)
                    if not valid:
                        failed_files.append(f"{relative_path}: {msg}")
                        continue
                    
                    # æ›´æ–°æ–‡ä»¶
                    success, result = await self.update_single_file(source_path, relative_path, user_id)
                    if success:
                        updated_files.append(relative_path)
                    else:
                        failed_files.append(f"{relative_path}: {result}")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            shutil.rmtree(extract_dir)
            
            # ç”Ÿæˆç»“æœæŠ¥å‘Š
            result_msg = f"å‹ç¼©åŒ…å¤„ç†å®Œæˆ\n"
            result_msg += f"âœ… æˆåŠŸæ›´æ–°: {len(updated_files)} ä¸ªæ–‡ä»¶\n"
            result_msg += f"âŒ å¤±è´¥: {len(failed_files)} ä¸ªæ–‡ä»¶\n"
            
            if updated_files:
                result_msg += f"\nğŸ“ å·²æ›´æ–°æ–‡ä»¶:\n" + "\n".join(f"â€¢ {f}" for f in updated_files)
            
            if failed_files:
                result_msg += f"\nâš ï¸ å¤±è´¥æ–‡ä»¶:\n" + "\n".join(f"â€¢ {f}" for f in failed_files)
            
            success = len(updated_files) > 0
            return success, result_msg
            
        except Exception as e:
            logger.error(f"å‹ç¼©åŒ…å¤„ç†å¤±è´¥: {e}")
            return False, f"å‹ç¼©åŒ…å¤„ç†å¤±è´¥: {str(e)}"
        finally:
            # ç¡®ä¿æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(extract_dir):
                shutil.rmtree(extract_dir, ignore_errors=True)
    
    def get_update_history(self, limit: int = 10) -> List[Dict]:
        """è·å–æ–‡ä»¶æ›´æ–°å†å²"""
        try:
            # ä»æ•°æ®åº“è·å–æ›´æ–°è®°å½•
            cursor = self.db.conn.cursor()
            cursor.execute("""
                SELECT config_key, config_value, updated_by, updated_time 
                FROM system_config 
                WHERE config_key LIKE 'file_update_%' 
                ORDER BY updated_time DESC 
                LIMIT ?
            """, (limit,))
            
            records = cursor.fetchall()
            history = []
            
            for record in records:
                try:
                    file_name = record[0].replace('file_update_', '')
                    update_info = json.loads(record[1])
                    update_info['file_name'] = file_name
                    update_info['updated_by'] = record[2]
                    update_info['updated_time'] = record[3]
                    history.append(update_info)
                except:
                    continue
            
            return history
            
        except Exception as e:
            logger.error(f"è·å–æ›´æ–°å†å²å¤±è´¥: {e}")
            return []
    
    def suggest_restart_bots(self, updated_files: List[str]) -> List[str]:
        """å»ºè®®éœ€è¦é‡å¯çš„æœºå™¨äºº"""
        restart_suggestions = []
        
        bot_file_mapping = {
            'submission_bot.py': 'submission',
            'publish_bot.py': 'publish', 
            'control_bot.py': 'control',
            'database.py': ['submission', 'publish', 'control'],
            'config_manager.py': ['submission', 'publish', 'control'],
            'hot_update_service.py': 'control',
            'update_service.py': 'control',
            'file_update_service.py': 'control',
            'notification_service.py': ['submission', 'publish'],
            'config.ini': ['submission', 'publish', 'control']
        }
        
        bots_to_restart = set()
        
        for file_name in updated_files:
            base_name = Path(file_name).name
            if base_name in bot_file_mapping:
                mapping = bot_file_mapping[base_name]
                if isinstance(mapping, list):
                    bots_to_restart.update(mapping)
                else:
                    bots_to_restart.add(mapping)
        
        return list(bots_to_restart)
    
    def cleanup_temp_files(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            if os.path.exists(self.temp_dir):
                # åˆ é™¤è¶…è¿‡1å°æ—¶çš„ä¸´æ—¶æ–‡ä»¶
                current_time = datetime.now()
                for item in os.listdir(self.temp_dir):
                    item_path = os.path.join(self.temp_dir, item)
                    if os.path.isfile(item_path):
                        file_time = datetime.fromtimestamp(os.path.getctime(item_path))
                        if (current_time - file_time).total_seconds() > 3600:  # 1å°æ—¶
                            os.remove(item_path)
                            logger.info(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {item_path}")
        except Exception as e:
            logger.error(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")